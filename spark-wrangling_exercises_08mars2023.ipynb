{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592d050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "\n",
    "import env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f65eeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 12:08:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/08 12:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/08 12:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/03/08 12:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "# spark object\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# When using Spark on the job, you'll work with the operations \n",
    " # team to install the right Java drivers and configure your connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc7844",
   "metadata": {},
   "source": [
    "## 1 / Read the cases, department, and source data into their own spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d94c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing 'case'\n",
    "\n",
    "query = \"\"\"SELECT * FROM cases \"\"\"\n",
    "url = env.get_connection(\"311_data\")\n",
    "\n",
    "case_df = pd.read_sql(query, url)\n",
    "case_df = spark.createDataFrame(case_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b2b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 1]\r",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 12:11:19 WARN TaskSetManager: Stage 0 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/03/08 12:11:23 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 0 (TID 0): Attempting to kill Python Worker\n",
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 1/1/18 0:42          \n",
      " case_closed_date     | 1/1/18 12:29         \n",
      " SLA_due_date         | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " SLA_days             | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      "-RECORD 1------------------------------------\n",
      " case_id              | 1014127333           \n",
      " case_opened_date     | 1/1/18 0:46          \n",
      " case_closed_date     | 1/3/18 8:11          \n",
      " SLA_due_date         | 1/5/18 8:30          \n",
      " case_late            | NO                   \n",
      " num_days_late        | -2.012604167         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Storm Water          \n",
      " service_request_type | Removal Of Obstru... \n",
      " SLA_days             | 4.322222222          \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMSS             \n",
      " request_address      | 2215  GOLIAD RD, ... \n",
      " council_district     | 3                    \n",
      "-RECORD 2------------------------------------\n",
      " case_id              | 1014127334           \n",
      " case_opened_date     | 1/1/18 0:48          \n",
      " case_closed_date     | 1/2/18 7:57          \n",
      " SLA_due_date         | 1/5/18 8:30          \n",
      " case_late            | NO                   \n",
      " num_days_late        | -3.022337963         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Storm Water          \n",
      " service_request_type | Removal Of Obstru... \n",
      " SLA_days             | 4.320729167          \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMSS             \n",
      " request_address      | 102  PALFREY ST W... \n",
      " council_district     | 3                    \n",
      "-RECORD 3------------------------------------\n",
      " case_id              | 1014127335           \n",
      " case_opened_date     | 1/1/18 1:29          \n",
      " case_closed_date     | 1/2/18 8:13          \n",
      " SLA_due_date         | 1/17/18 8:30         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -15.01148148         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Code Enforcement     \n",
      " service_request_type | Front Or Side Yar... \n",
      " SLA_days             | 16.29188657          \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMSS             \n",
      " request_address      | 114  LA GARDE ST,... \n",
      " council_district     | 3                    \n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "case_df.show(4, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e15140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "|       dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "|     311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|               Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|     Clean and Green|Parks and Recreation|    Parks & Recreation|                YES|\n",
      "|Clean and Green N...|Parks and Recreation|    Parks & Recreation|                YES|\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing 'source'\n",
    "\n",
    "query = \"\"\"SELECT * FROM dept\"\"\"\n",
    "url = env.get_connection(\"311_data\")\n",
    "\n",
    "dept_df = pd.read_sql(query, url)\n",
    "dept_df = spark.createDataFrame(dept_df)\n",
    "dept_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6beecdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------------+\n",
      "|index|source_id| source_username|\n",
      "+-----+---------+----------------+\n",
      "|    0|   100137|Merlene Blodgett|\n",
      "|    1|   103582|     Carmen Cura|\n",
      "|    2|   106463| Richard Sanchez|\n",
      "|    3|   119403|  Betty De Hoyos|\n",
      "+-----+---------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing 'source'\n",
    "\n",
    "query = \"\"\"SELECT * FROM source\"\"\"\n",
    "url = env.get_connection(\"311_data\")\n",
    "\n",
    "source_df = pd.read_sql(query, url)\n",
    "source_df = spark.createDataFrame(source_df)\n",
    "source_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7582f1e",
   "metadata": {},
   "source": [
    "## 2 / Let's see how writing to the local disk works in spark:\n",
    "\n",
    "    Write the code necessary to store the source data in both csv and json format, \n",
    "     store these as sources_csv and sources_json.\n",
    "    Inspect your folder structure. What do you notice?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad0052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 12:11:28 WARN TaskSetManager: Stage 4 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# storing cases as .json\n",
    "\n",
    "case_df.write.json('data/cases_json', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b091ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 12:17:13 WARN TaskSetManager: Stage 6 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# storing cases as .csv\n",
    "\n",
    "(case_df.write.format('csv')\n",
    " .mode('overwrite')\n",
    " .option('header', 'true')\n",
    " .save('data/case_csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f676fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read .csv\n",
    "\n",
    "c = spark.read.json('data/cases_json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "361b90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " SLA_days             | 7.0                  \n",
      " SLA_due_date         | 10/16/17 9:21        \n",
      " case_closed          | YES                  \n",
      " case_closed_date     | 10/18/17 14:42       \n",
      " case_id              | 1013935522           \n",
      " case_late            | YES                  \n",
      " case_opened_date     | 10/9/17 9:21         \n",
      " case_status          | Closed               \n",
      " council_district     | 1                    \n",
      " dept_division        | Waste Collection     \n",
      " num_days_late        | 2.222581019          \n",
      " request_address      | 1803  POPLAR ST W... \n",
      " service_request_type | Automation Proper... \n",
      " source_id            | 138810               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "962a771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get headers to appear when reading in .csv files\n",
    "\n",
    "cc = spark.read.csv('data/case_csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cea58a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " case_id              | 1013935522           \n",
      " case_opened_date     | 10/9/17 9:21         \n",
      " case_closed_date     | 10/18/17 14:42       \n",
      " SLA_due_date         | 10/16/17 9:21        \n",
      " case_late            | YES                  \n",
      " num_days_late        | 2.222581019          \n",
      " case_closed          | YES                  \n",
      " dept_division        | Waste Collection     \n",
      " service_request_type | Automation Proper... \n",
      " SLA_days             | 7.0                  \n",
      " case_status          | Closed               \n",
      " source_id            | 138810               \n",
      " request_address      | 1803  POPLAR ST W... \n",
      " council_district     | 1                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0536d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing dept as .json\n",
    "\n",
    "dept_df.write.json('data/dept_json', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea74b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing dept as .csv\n",
    "\n",
    "dept_df.write.csv('data/dept_csv', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8cc44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing sources as json\n",
    "\n",
    "(source_df.write.format('json')\n",
    " .mode('overwrite')\n",
    " .option('header', 'true')\n",
    " .save('data/source_json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe39132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing sources as csv\n",
    "\n",
    "(source_df.write.format('csv')\n",
    " .mode('overwrite')\n",
    " .option('header', 'true')\n",
    " .save('data/source_csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982523c",
   "metadata": {},
   "source": [
    "## 3 / Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d7b5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: long (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- source_username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# source_df dtypes\n",
    "\n",
    "source_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e85bd",
   "metadata": {},
   "source": [
    "These data types look appropriate, though 'index' could be recast as a ShortType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b169d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: short (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- source_username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recasting 'index'\n",
    "\n",
    "source_df = source_df.withColumn(\"index\", col(\"index\").cast(\"short\"))\n",
    "source_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5de17a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: long (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case_df dtypes\n",
    "\n",
    "case_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177cedae",
   "metadata": {},
   "source": [
    "The dates are all strings. They should be changed to datetime format.  \n",
    "case_id could also be changed to ShortType and 'council_district' to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ce36bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recasting 'case_id' to ShortType and 'council_district' to string\n",
    "\n",
    "case_df = case_df.withColumn(\"case_id\", col(\"case_id\").cast(\"short\"))\n",
    "case_df = case_df.withColumn('council_district', col('council_district').cast('string'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c2a2568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: short (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5ef9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing to DateTime format\n",
    "\n",
    "\n",
    "cur_fmt = 'M/d/yy H:mm'\n",
    "\n",
    "case_df = (\n",
    "            case_df.withColumn('case_opened_date', to_timestamp('case_opened_date', cur_fmt))\n",
    "                         .withColumn('case_closed_date', to_timestamp('case_closed_date', cur_fmt))\n",
    "                         .withColumn('SLA_due_date', to_timestamp('SLA_due_date', cur_fmt))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "674ce181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 12:23:45 WARN TaskSetManager: Stage 16 contains a task of very large size (18865 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 12:23:50 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 16 (TID 72): Attempting to kill Python Worker\n",
      "+-------------------+-------------------+-------------------+\n",
      "|   case_opened_date|   case_closed_date|       SLA_due_date|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2018-01-01 00:42:00|2018-01-01 12:29:00|2020-09-26 00:42:00|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "case_df.select(\"case_opened_date\", \"case_closed_date\", \"SLA_due_date\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "395d33f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- standardized_dept_name: string (nullable = true)\n",
      " |-- dept_subject_to_SLA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dept_df dtypes\n",
    "\n",
    "dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a9967b",
   "metadata": {},
   "source": [
    "These all look fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07343d65",
   "metadata": {},
   "source": [
    "# 1 / How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b145e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb2d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
